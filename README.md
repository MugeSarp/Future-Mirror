# Future Mirror

## Project Description

Future Mirror is an AI-based web application designed to visualize how something might look 20 years from now, using only a text input. Whether it's a person, an animal, or an abstract concept, users can describe it and receive a highly detailed future-themed image in return.

## Features

- Uses a language model to transform a basic prompt into a more descriptive, future-themed sentence.
- Generates a corresponding image using a diffusion-based text-to-image model (Stable Diffusion).
- Web interface with:
  - Text input for prompts
  - Display of generated image
  - Description shown under the image
  - Download button for saving the image
- Designed to be mobile-responsive for a smooth experience across devices.

## Technologies Used

- Python
- Hugging Face Transformers
- Diffusers (Stable Diffusion)
- Streamlit (Web Interface)
- Google Colab (GPU access)

## Instructions

1. Enter a simple prompt (e.g., "a cat", "a city").
2. The language model will expand it into a detailed description imagining it 20 years into the future.
3. This description will be used to generate an image.
4. View and optionally download the result.

## Sample Outputs

- "A futuristic city with flying cars and neon skies" → *[Image of the output]*
- "A lion evolved into a cybernetic jungle predator" → *[Image of the output]*

## About the Developer

- Name: Müge Sarp  
- University: Eastern Mediterranean University  
- Department: Computer Engineering  
- Year: 3rd Year  
- Project Name: Future Mirror  
- Date: April 2025
